import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import joblib
import os
import re
import time
import optuna
from sklearn.preprocessing import LabelEncoder
import lightgbm as lgb
from tabulate import tabulate
import warnings
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# è­¦å‘Šã‚’éè¡¨ç¤º
warnings.filterwarnings('ignore')

class KeibaSystem:
    def __init__(self, csv_path='all_keiba_results.csv'):
        self.csv_path = csv_path

        # â˜… è¿½åŠ : äºˆæƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        self.log_path = 'prediction_log.csv'

        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        # â˜… ç‰¹å¾´é‡å®šç¾© (26å€‹)
        self.features = [
            'æ  ç•ª', 'é¦¬ ç•ª', 'æ–¤é‡', 'ä½“é‡', 'ä½“é‡å¢—æ¸›', 'é¨æ‰‹ID', 'å ´ID', 'é¦¬å ´ID', 'ãƒˆãƒ©ãƒƒã‚¯ID',
            'é¦¬_å‰3èµ°å¹³å‡ç€é †', 'é¦¬_åŒå ´è¤‡å‹ç‡', 'é¦¬_åŒé¦¬å ´è¤‡å‹ç‡', 'ãƒ¬ãƒ¼ã‚¹ç•ªå·', 'ã‚¯ãƒ©ã‚¹ãƒã‚§ãƒ³ã‚¸', 
            'æ–¤é‡å¤‰åŒ–', 'è·é›¢å¤‰åŒ–', 'å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°', 'ã‚¿ã‚¤ãƒ æŒ‡æ•°é †ä½', 'å‰èµ°ç€é †é †ä½', 'é¨æ‰‹ã®å‹¢ã„',
            'è·é›¢å¤‰åŒ–åŒºåˆ†', 'ç€é †å¤‰å‹•', 'ä¹—ã‚Šæ›¿ã‚ã‚Š', 'é¨æ‰‹_æœ¬è³_é€£å¯¾ç‡', 
            'ã‚¿ã‚¤ãƒ æŒ‡æ•°_ãƒ¬ãƒ¼ã‚¹å†…å·®', 'æ–¤é‡_ãƒ¬ãƒ¼ã‚¹å†…å·®'
        ]

        print("ğŸ“ ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        if os.path.exists(self.csv_path):
            self.history_df = pd.read_csv(self.csv_path, dtype={'race_id': str})
            self.history_df = self.history_df.dropna(subset=['race_id'])
            print(f"   éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.history_df)} è¡Œ")
        else:
            print("   éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
            self.history_df = pd.DataFrame()

        # LightGBMã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.best_params = {
            'objective': 'lambdarank', 
            'metric': 'ndcg', 
            'ndcg_eval_at': [1, 3],
            'verbosity': -1, 
            'boosting_type': 'gbdt', 
            'random_state': 42,
            'learning_rate': 0.05, 
            'num_leaves': 31,
            'max_depth': 7, 
            'min_child_samples': 20, 
            'subsample': 0.8,
            'colsample_bytree': 0.8
        }
        
        self.models = self.load_models()
        
        # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ãˆrwfm
        self.place_dict = {"01":"æœ­å¹Œ","02":"å‡½é¤¨","03":"ç¦å³¶","04":"æ–°æ½Ÿ","05":"æ±äº¬","06":"ä¸­å±±","07":"ä¸­äº¬","08":"äº¬éƒ½","09":"é˜ªç¥","10":"å°å€‰"}
        self.cond_dict = {"è‰¯": "è‰¯", "ç¨": "ç¨é‡", "é‡": "é‡", "ä¸": "ä¸è‰¯"}
        self.weather_list = ["æ™´", "æ›‡", "é›¨", "å°é›¨", "é›ª", "å°é›ª"]
        
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•å®Œäº†ã€‚")

    def load_models(self):
        models = []
        seeds = [42, 100, 2024]
        for seed in seeds:
            path = f'production_model_2026_seed_{seed}.pkl'
            if os.path.exists(path):
                try:
                    models.append(joblib.load(path))
                except:
                    print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ« {path} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
        return models

    # ==========================================
    # ãƒ‡ãƒ¼ã‚¿åŠ å·¥ãƒ­ã‚¸ãƒƒã‚¯ (ç‰¹å¾´é‡ç”Ÿæˆ)
    # ==========================================
    def process_data(self, df):
        df = df.copy()
        if 'race_id' not in df.columns: return df
        
        # race_idã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        df['race_id'] = df['race_id'].astype(str).str.replace('.0', '', regex=False)
        df = df[df['race_id'] != 'nan']
        
        if len(df) == 0: return df

        # --- æ•°å€¤å¤‰æ›ãƒ˜ãƒ«ãƒ‘ãƒ¼ ---
        def time_to_seconds(time_str):
            try:
                if pd.isna(time_str): return None
                s_str = str(time_str)
                if ':' in s_str:
                    m, s = s_str.split(':')
                    return int(m) * 60 + float(s)
                return float(s_str)
            except: return None

        def split_weight(weight_str):
            try:
                s_weight = str(weight_str)
                if pd.isna(s_weight) or 'è¨ˆä¸' in s_weight: return 470, 0
                w = s_weight.split('(')[0]
                diff = s_weight.split('(')[1].replace(')', '') if '(' in s_weight else 0
                return int(w), int(diff)
            except: return 470, 0

        # --- åŸºæœ¬åˆ—ã®å‡¦ç† ---
        if 'é¦¬ä½“é‡' in df.columns:
            df['ä½“é‡'], df['ä½“é‡å¢—æ¸›'] = zip(*df['é¦¬ä½“é‡'].apply(split_weight))
        else:
            df['ä½“é‡'], df['ä½“é‡å¢—æ¸›'] = 470, 0

        if 'ã‚¿ã‚¤ãƒ ' in df.columns:
            df['ã‚¿ã‚¤ãƒ ç§’'] = df['ã‚¿ã‚¤ãƒ '].apply(time_to_seconds)
        
        cols = ['å˜å‹', 'äºº æ°—', 'ç€ é †', 'æ  ç•ª', 'é¦¬ ç•ª', 'æ–¤é‡']
        for col in cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•° (ç€é †)
        if 'ç€ é †' in df.columns:
            df['is_top3'] = df['ç€ é †'].apply(lambda x: 1 if x <= 3 else 0)
            df['is_win'] = (df['ç€ é †'] == 1).astype(int)
            df['rank_label'] = (18 - df['ç€ é †']).clip(lower=0)

        # --- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (Base) ---
        # ãƒ¬ãƒ¼ã‚¹ç•ªå·æŠ½å‡º
        try:
            df['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = df['race_id'].str[-2:].astype(int)
        except:
            df['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = 11

        # ã‚½ãƒ¼ãƒˆã—ã¦éå»æˆç¸¾ã‚’è¨ˆç®— (é¦¬ã”ã¨ã®æ™‚ç³»åˆ—)
        df = df.sort_values(['é¦¬å', 'race_id'])

        # --- 1. éå»æˆç¸¾ & ãƒˆãƒ¬ãƒ³ãƒ‰ (Trend) ---
        df['é¦¬_å‰3èµ°å¹³å‡ç€é †'] = df.groupby('é¦¬å')['ç€ é †'].transform(lambda x: x.shift(1).rolling(3).mean())
        df['é¦¬_åŒå ´è¤‡å‹ç‡'] = df.groupby(['é¦¬å', 'site'])['is_top3'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)
        df['é¦¬_åŒé¦¬å ´è¤‡å‹ç‡'] = df.groupby(['é¦¬å', 'condition'])['is_top3'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)
        
        # ã‚¿ã‚¤ãƒ æŒ‡æ•°
        if 'ã‚¿ã‚¤ãƒ ç§’' in df.columns:
            # ãã®ãƒ¬ãƒ¼ã‚¹ã®å¹³å‡ã‚¿ã‚¤ãƒ ã¨ã®å·®
            race_avg_time = df.groupby('race_id')['ã‚¿ã‚¤ãƒ ç§’'].transform('mean')
            df['ã‚¿ã‚¤ãƒ æŒ‡æ•°'] = race_avg_time - df['ã‚¿ã‚¤ãƒ ç§’'] 
            # å‰èµ°ã®æŒ‡æ•°ã‚’å–å¾—
            df['å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°'] = df.groupby('é¦¬å')['ã‚¿ã‚¤ãƒ æŒ‡æ•°'].shift(1)
        
        # å¤‰åŒ–é‡ãƒ»å‹¢ã„
        df['æ–¤é‡å¤‰åŒ–'] = df.groupby('é¦¬å')['æ–¤é‡'].diff().fillna(0)
        df['è·é›¢å¤‰åŒ–'] = df.groupby('é¦¬å')['distance'].diff().fillna(0)
        # è·é›¢å¤‰åŒ–ã‚’ã‚«ãƒ†ã‚´ãƒªåŒ– (1:å»¶é•·, -1:çŸ­ç¸®, 0:åŒè·é›¢)
        df['è·é›¢å¤‰åŒ–åŒºåˆ†'] = df['è·é›¢å¤‰åŒ–'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))
        
        # ç€é †ã®æ¨ç§» (å‰èµ° - 2èµ°å‰) ãƒã‚¤ãƒŠã‚¹ãªã‚‰è‰¯åŒ–
        df['2èµ°å‰ç€é †'] = df.groupby('é¦¬å')['ç€ é †'].shift(2)
        df['ç€é †å¤‰å‹•'] = df.groupby('é¦¬å')['ç€ é †'].shift(1) - df['2èµ°å‰ç€é †']
        
        # ã‚¯ãƒ©ã‚¹ãƒ»é¨æ‰‹
        df['å‰èµ°_ãƒ¬ãƒ¼ã‚¹ç•ªå·'] = df.groupby('é¦¬å')['ãƒ¬ãƒ¼ã‚¹ç•ªå·'].shift(1)
        df['ã‚¯ãƒ©ã‚¹ãƒã‚§ãƒ³ã‚¸'] = df['ãƒ¬ãƒ¼ã‚¹ç•ªå·'] - df['å‰èµ°_ãƒ¬ãƒ¼ã‚¹ç•ªå·'].fillna(df['ãƒ¬ãƒ¼ã‚¹ç•ªå·'])
        
        # é¨æ‰‹ã®å‹¢ã„ (ç›´è¿‘20èµ°)
        df['é¨æ‰‹ã®å‹¢ã„'] = df.groupby('é¨æ‰‹')['is_win'].transform(lambda x: x.shift(1).rolling(20).mean()).fillna(0)
        
        # --- 2. é¨æ‰‹ãƒ»ç›¸æ€§ (Interaction) ---
        # ä¹—ã‚Šæ›¿ã‚ã‚Šãƒ•ãƒ©ã‚°
        df['å‰èµ°é¨æ‰‹'] = df.groupby('é¦¬å')['é¨æ‰‹'].shift(1)
        df['ä¹—ã‚Šæ›¿ã‚ã‚Š'] = (df['é¨æ‰‹'] != df['å‰èµ°é¨æ‰‹']).astype(int)
        
        # é¨æ‰‹Ã—ã‚³ãƒ¼ã‚¹ç›¸æ€§ (åŒå ´é€£å¯¾ç‡)
        df['é¨æ‰‹_æœ¬è³_é€£å¯¾ç‡'] = df.groupby(['é¨æ‰‹', 'site'])['is_top3'].transform(lambda x: x.shift(1).expanding().mean()).fillna(0)

        # --- 3. ãƒ¬ãƒ¼ã‚¹å†…ç›¸å¯¾è©•ä¾¡ (Context) ---
        # ã“ã“ã‹ã‚‰ã¯ãƒ¬ãƒ¼ã‚¹å˜ä½ã§æ¯”è¼ƒã™ã‚‹ãŸã‚ã‚½ãƒ¼ãƒˆé †ã‚’å¤‰æ›´
        df = df.sort_values(['race_id', 'é¦¬ ç•ª'])
        
        # å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°ã®ãƒ¬ãƒ¼ã‚¹å†…åå·®å€¤åŒ– (å¹³å‡ã¨ã®å·®)
        # â€» fillna(0) ã¯åˆå‡ºèµ°ãªã©ã§ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
        df['ã‚¿ã‚¤ãƒ æŒ‡æ•°_ãƒ¬ãƒ¼ã‚¹å†…å·®'] = df.groupby('race_id')['å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°'].transform(lambda x: x - x.mean()).fillna(0)
        
        # æ–¤é‡ã®ãƒ¬ãƒ¼ã‚¹å†…æ¯”è¼ƒ (å‘¨ã‚Šã‚ˆã‚Šé‡ã„ã‹è»½ã„ã‹)
        df['æ–¤é‡_ãƒ¬ãƒ¼ã‚¹å†…å·®'] = df.groupby('race_id')['æ–¤é‡'].transform(lambda x: x - x.mean())

        # æ—¢å­˜ã®é †ä½ç³»
        df['ã‚¿ã‚¤ãƒ æŒ‡æ•°é †ä½'] = df.groupby('race_id')['å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°'].rank(ascending=False)
        df['å‰èµ°ç€é †é †ä½'] = df.groupby('race_id')['é¦¬_å‰3èµ°å¹³å‡ç€é †'].rank(ascending=True)

        # Label Encoding
        le = LabelEncoder()
        for col in ['site', 'condition', 'track', 'é¨æ‰‹']:
            df[col] = df[col].astype(str).fillna('unknown')
            id_col = col + 'ID' if col != 'site' else 'å ´ID'
            if col == 'condition': id_col = 'é¦¬å ´ID'
            if col == 'track': id_col = 'ãƒˆãƒ©ãƒƒã‚¯ID'
            # æœªçŸ¥ã®ãƒ©ãƒ™ãƒ«å¯¾å¿œã®ãŸã‚fitæ¸ˆã¿ã®ã‚‚ã®ã¯ä½¿ã‚ãšæ¯å›å¤‰æ›(ç°¡æ˜“çš„)
            df[id_col] = le.fit_transform(df[col])

        return df

    # ==========================================
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ˜ãƒ«ãƒ‘ãƒ¼
    # ==========================================
    def get_race_info(self, soup):
        try:
            text = ""
            data_intro = soup.find('div', class_='RaceData01')
            if data_intro: text = data_intro.get_text(strip=True)
            else:
                data_intro_res = soup.find('div', class_='data_intro')
                if data_intro_res: text = data_intro_res.get_text(strip=True)

            if not text: return "èŠ", 1600, "æ™´", "è‰¯"

            track = "èŠ" if "èŠ" in text else "ãƒ€ãƒ¼ãƒˆ" if "ãƒ€" in text else "éšœå®³"
            dist_match = re.search(r"(\d+)m", text)
            distance = int(dist_match.group(1)) if dist_match else 1600
            
            weather = "æ™´"
            for w in self.weather_list:
                if w in text: weather = w; break
            
            condition = "è‰¯"
            for k, v in self.cond_dict.items():
                if k in text: condition = v; break
            
            return track, distance, weather, condition
        except: return "èŠ", 1600, "æ™´", "è‰¯"

    def fetch_race_data(self, race_id, mode='shutuba'):
        time.sleep(1) # ãƒãƒŠãƒ¼ã¨ã—ã¦1ç§’å¾…æ©Ÿ
        url_base = "https://race.netkeiba.com/race/shutuba.html" if mode == 'shutuba' else "https://race.netkeiba.com/race/result.html"
        url = f"{url_base}?race_id={race_id}"
        try:
            res = requests.get(url, headers=self.headers)
            res.encoding = 'EUC-JP'
            if len(res.text) < 500: return None, None, None
            soup = BeautifulSoup(res.text, 'html.parser')
            track, distance, weather, condition = self.get_race_info(soup)
            
            dfs = pd.read_html(res.text)
            raw_df = None
            for d in dfs:
                # åˆ—åã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° (æ”¹è¡Œã‚„ã‚¹ãƒšãƒ¼ã‚¹ã‚’å‰Šé™¤)
                if isinstance(d.columns, pd.MultiIndex): 
                    d.columns = [str(c[0]).replace('\n','').replace(' ','') for c in d.columns]
                else:
                    d.columns = [str(c).replace('\n','').replace(' ','') for c in d.columns]
                
                # é¦¬åãŒã‚ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
                if 'é¦¬å' in d.columns: 
                    raw_df = d; break
            
            return raw_df, (track, distance, weather, condition), soup
        except: return None, None, None

    # ==========================================
    # â˜… Seleniumã‚’ä½¿ã£ãŸå¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿å–å¾— (æ–°è¦è¿½åŠ )
    # ==========================================
    def fetch_data_selenium(self, race_id):
        print("   ğŸŒ Seleniumã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        # ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®š (ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰: ç”»é¢ã‚’è¡¨ç¤ºã›ãšã«å®Ÿè¡Œ)
        options = Options()
        options.add_argument('--headless') # ç”»é¢ã‚’å‡ºã—ãŸã„å ´åˆã¯ã“ã®è¡Œã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå½è£…
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

        driver = webdriver.Chrome(options=options)
        wait = WebDriverWait(driver, 20)
        
        url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
        
        try:
            driver.get(url)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.ShutubaTable')))
            
            # ãƒšãƒ¼ã‚¸ã®ã‚½ãƒ¼ã‚¹ã‚’BeautifulSoupã«æ¸¡ã™
            soup = BeautifulSoup(driver.page_source, 'lxml')
            
            # --- ã“ã“ã‹ã‚‰ã”æç¤ºã®ã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ ---
            shutuba_table = []
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼å–å¾—
            header_tr = soup.select_one('.ShutubaTable > thead > tr')
            if header_tr:
                headers = [th.text.strip().split('\n')[0] for th in header_tr.select('th')]
                # ä½™è¨ˆãªåˆ—ãŒã‚ã‚Œã°èª¿æ•´ (å‚ç…§ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦11åˆ—ç›®ã¾ã§ãªã©)
                # headers = headers[:15] 
                shutuba_table.append(headers)
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œå–å¾—
            rows = soup.select('.ShutubaTable > tbody > tr')
            for tr in rows:
                row_data = []
                tds = tr.select('td')
                
                # é¦¬ç•ªã€é¦¬åã€ã‚ªãƒƒã‚ºãªã©ãŒå«ã¾ã‚Œã‚‹ä¸»è¦ãªåˆ—ã‚’å–å¾—
                for i, td in enumerate(tds):
                    # å°ã®åˆ—ãªã©ã¯ãƒ†ã‚­ã‚¹ãƒˆãŒç‰¹æ®Šãªå ´åˆãŒã‚ã‚‹ãŒã€åŸºæœ¬ã¯text.strip()
                    txt = td.text.strip()
                    
                    # ã‚ªãƒƒã‚ºåˆ—(äººæ°—é †ãªã©ãŒå…¥ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã‚¯ãƒ©ã‚¹ã§åˆ¤åˆ¥ã‚‚å¯ã ãŒã€é †ç•ªã§å–ã‚‹)
                    # å‚ç…§ã‚³ãƒ¼ãƒ‰ã§ã¯ td.select_one('.selectBox') ãªã©ã®å‡¦ç†ãŒã‚ã£ãŸã®ã§è¸è¥²
                    if 'selectBox' in str(td):
                        val = td.select_one('.selectBox')
                        txt = val.text.strip() if val else '--'
                    
                    # ã‚ªãƒƒã‚ºãŒ "---" ã®å ´åˆã‚„ã€æ›´æ–°ä¸­ãªã©ã®æ”¹è¡Œã‚’é™¤å»
                    txt = txt.split('\n')[0]
                    row_data.append(txt)
                
                shutuba_table.append(row_data)
                
            return shutuba_table, soup

        except Exception as e:
            print(f"   âš ï¸ Seleniumã‚¨ãƒ©ãƒ¼: {e}")
            return None, None
        finally:
            driver.quit()

    # ==========================================
    # â˜… äºˆæƒ³æ©Ÿèƒ½ (Selenium / åˆ—ã‚ºãƒ¬é˜²æ­¢ãƒ»å®Œå…¨ç‰ˆ)
    # ==========================================
    def predict_race(self, race_id):
        if not self.models:
            print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œ3ã€ã‚’é¸æŠã—ã¦å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
            return

        print(f"\nğŸš€ ãƒ¬ãƒ¼ã‚¹ID {race_id} ã®äºˆæƒ³ã‚’é–‹å§‹ã—ã¾ã™ (Selenium Mode)")

        # 1. Seleniumã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        data_list, soup = self.fetch_data_selenium(race_id)
        
        if not data_list or len(data_list) < 2:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return

        # 2. DataFrameåŒ– (ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä¿¡ç”¨ã›ãšã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½ç½®ã§å¼·åˆ¶ãƒãƒƒãƒ”ãƒ³ã‚°)
        # Netkeibaã®å‡ºé¦¬è¡¨ã®æ¨™æº–çš„ãªä¸¦ã³é † (0å§‹ã¾ã‚Š):
        # 0:æ , 1:é¦¬ç•ª, 2:å°, 3:é¦¬å, 4:æ€§é½¢, 5:æ–¤é‡, 6:é¨æ‰‹, 7:å©èˆ, 8:ä½“é‡, 9:ã‚ªãƒƒã‚º, 10:äººæ°—
        
        raw_data = data_list[1:] # ãƒ˜ãƒƒãƒ€ãƒ¼é™¤å¤–
        df = pd.DataFrame(raw_data)
        
        # åˆ—æ•°ãŒè¶³ã‚Šãªã„å ´åˆã®ã‚¬ãƒ¼ãƒ‰
        if len(df.columns) < 11:
            print(f"âš ï¸ åˆ—æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ (ç¾åœ¨: {len(df.columns)}åˆ—)ã€‚ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚")
            # è¶³ã‚Šãªã„åˆ—ã‚’ç©ºæ–‡å­—ã§åŸ‹ã‚ã‚‹
            for i in range(len(df.columns), 11):
                df[i] = ""

        # å¼·åˆ¶çš„ã«åˆ—åã‚’å‰²ã‚Šå½“ã¦ (åˆ—åã‚ºãƒ¬é˜²æ­¢ã®ãŸã‚ä½ç½®æŒ‡å®š)
        # å¿…è¦ãªåˆ—ã ã‘ã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã§æŠœãå‡ºã™
        df_clean = pd.DataFrame()
        df_clean['æ  ç•ª'] = df.iloc[:, 0]
        df_clean['é¦¬ ç•ª'] = df.iloc[:, 1]
        df_clean['é¦¬å']   = df.iloc[:, 3]
        df_clean['æ–¤é‡']   = df.iloc[:, 5]
        df_clean['é¨æ‰‹']   = df.iloc[:, 6]
        df_clean['å˜å‹']   = df.iloc[:, 9] # ã‚ªãƒƒã‚º
        df_clean['äºº æ°—']  = df.iloc[:, 10]
        
        # ä½“é‡ã®å‡¦ç† (8åˆ—ç›®)
        if len(df.columns) > 8:
            df_clean['é¦¬ä½“é‡'] = df.iloc[:, 8]
        else:
            df_clean['é¦¬ä½“é‡'] = "470(0)"

        df = df_clean.copy()

        # 3. æ•°å€¤å¤‰æ›ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° (ã“ã“ã§NaNã‚’æ’²æ»…ã™ã‚‹)
        def safe_float(x):
            try: return float(str(x).replace('---', '0'))
            except: return 0.0

        def safe_int(x):
            try: return int(float(str(x)))
            except: return 0

        # å˜å‹: "---" ã‚„æ–‡å­—åŒ–ã‘ã‚’ 0.0 ã«
        df['å˜å‹'] = df['å˜å‹'].apply(safe_float)
        
        # é¦¬ç•ª: æ•°å€¤åŒ–ã§ããªã„è¡Œã¯å‰Šé™¤ (ã“ã“ãŒé‡è¦)
        df['é¦¬ ç•ª'] = pd.to_numeric(df['é¦¬ ç•ª'], errors='coerce')
        df = df.dropna(subset=['é¦¬ ç•ª']) # é¦¬ç•ªãŒãªã„è¡Œã¯ã‚´ãƒŸãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ¨ã¦ã‚‹
        df['é¦¬ ç•ª'] = df['é¦¬ ç•ª'].astype(int)
        
        # æ–¤é‡
        df['æ–¤é‡'] = df['æ–¤é‡'].apply(safe_float)
        
        # äººæ°—
        df['äºº æ°—'] = df['äºº æ°—'].apply(safe_int)

        # æƒ…å ±å–å¾—
        track, distance, weather, condition = self.get_race_info(soup)
        place_code = race_id[4:6]
        site_name = self.place_dict.get(place_code, "æ±äº¬")
        
        print(f"   ğŸ“ {site_name} / {track} {distance}m / {weather} / {condition}")
        
        valid_odds = (df['å˜å‹'] > 0).sum()
        if valid_odds > 0:
            print(f"   âœ… ã‚ªãƒƒã‚ºå–å¾—æˆåŠŸ: {valid_odds}é ­")
        else:
            print("   âš ï¸ ã‚ªãƒƒã‚ºãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ (0.0ã¨ã—ã¦å‡¦ç†ã—ã¾ã™)")

        # -------------------------------------------------------
        # äºˆæ¸¬ãƒ—ãƒ­ã‚»ã‚¹
        # -------------------------------------------------------
        df['site'] = site_name
        df['distance'] = distance
        df['track'] = track
        df['condition'] = condition
        df['weather'] = weather
        df['race_id'] = str(race_id)
        
        # éå»ãƒ‡ãƒ¼ã‚¿çµåˆ
        full_df = pd.concat([self.history_df, df], axis=0).drop_duplicates(subset=['race_id', 'é¦¬å'], keep='last')
        processed_full = self.process_data(full_df)
        processed_df = processed_full[processed_full['race_id'] == str(race_id)].copy()
        
        if len(processed_df) == 0:
            print("âŒ å‡¦ç†ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ (é¦¬ç•ªã®ç‰¹å®šã«å¤±æ•—ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™)ã€‚")
            return

        preds = []
        try:
            for model in self.models:
                preds.append(model.predict(processed_df[self.features]))
        except Exception as e:
            print(f"âŒ äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        processed_df['score'] = np.mean(preds, axis=0)
        std = processed_df['score'].std()
        processed_df['score_z'] = (processed_df['score'] - processed_df['score'].mean()) / std if std != 0 else 0
        
        results = processed_df.copy().sort_values('score_z', ascending=False)
        
        # å‡ºåŠ›
        buy_list = []
        full_list = []
        
        for i, (_, row) in enumerate(results.iterrows()):
            score = row['score_z']
            odds_val = float(row['å˜å‹'])
            
            status = ""
            is_buy = False
            
            if score > 1.5:
                if odds_val == 0: status = "â³ å¾…æ©Ÿ"
                elif odds_val >= 30.0: status = "ğŸ§ª çˆ†ç©´"
                elif odds_val >= 5.0: status = "ğŸ”¥ğŸ”¥ å¦™å‘³"
                else: status = "âš ï¸ æœ¬å‘½"
                if odds_val > 0: is_buy = True
            elif score > 0.8:
                status = "â–³ æŠ‘ãˆ"

            odds_str = f"{odds_val:.1f}" if odds_val > 0 else "--"
            
            # ã€ä¿®æ­£ã€‘ã“ã“ã§ã‚‚å¿µã®ãŸã‚å®‰å…¨ã«å¤‰æ›
            try:
                umaban = int(row['é¦¬ ç•ª'])
            except:
                umaban = 0

            row_data = [i+1, umaban, row['é¦¬å'], f"{score:.2f}", odds_str, status]
            full_list.append(row_data)
            if is_buy: buy_list.append(row_data)

        headers = ["Rank", "No.", "Name", "AI(Z)", "Odds", "Status"]
        
        print("\n" + "="*55)
        print(" ğŸ¯ æ¨å¥¨é¦¬ (Buying Target)")
        print("="*55)
        if buy_list:
            print(tabulate(buy_list, headers=headers, tablefmt="fancy_grid"))
        else:
            print("   (æ¨å¥¨é¦¬ãªã—)")

        print("\n" + "-"*55)
        print(" ğŸ“‹ å…¨é ­åˆ†æ")
        print("-"*55)
        print(tabulate(full_list, headers=headers, tablefmt="simple"))

        # â˜… è¿½åŠ : äºˆæƒ³çµæœã‚’CSVã«ä¿å­˜
        # results ã¨ã„ã†å¤‰æ•°ãŒã‚½ãƒ¼ãƒˆæ¸ˆã¿ã®çµæœDataFrameã¨ã—ã¦å­˜åœ¨ã—ã¦ã„ã‚‹ç®‡æ‰€ã‚’åˆ©ç”¨
        if 'results' in locals():
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ—ã‚’è¿½åŠ ã—ã¦ã‹ã‚‰ä¿å­˜
            # (predict_raceå†…ã®ãƒ«ãƒ¼ãƒ—ã§åˆ¤å®šã—ãŸstatusã‚’DataFrameã«æˆ»ã™ã®ã¯æ‰‹é–“ãªã®ã§
            #  ç°¡æ˜“çš„ã«ã“ã“ã§å†è¨ˆç®—ã™ã‚‹ã‹ã€ãƒ«ãƒ¼ãƒ—å†…ã§ãƒªã‚¹ãƒˆåŒ–ã—ãŸã‚‚ã®ã‚’DataFrameåŒ–ã™ã‚‹ã®ãŒå®‰å…¨ã§ã™ãŒ
            #  ã“ã“ã§ã¯results DataFrameã«æœ€ä½é™ã®æƒ…å ±ã‚’ä»˜ä¸ã—ã¦æ¸¡ã—ã¾ã™)
            
            # ç°¡æ˜“å®Ÿè£…: results DFã«ã¯ statusåˆ—ãŒãªã„ã®ã§ã€ã“ã“ã§è¨ˆç®—ã—ã¦ä»˜ä¸
            def get_status(row):
                s = row['score_z']
                o = float(row['å˜å‹'])
                if s > 1.5:
                    if o >= 30: return "çˆ†ç©´"
                    elif o >= 5: return "å¦™å‘³"
                    return "æœ¬å‘½"
                elif s > 0.8: return "æŠ‘ãˆ"
                return "-"
                
            results['status'] = results.apply(get_status, axis=1)
            self.save_prediction_log(race_id, results)

            # â˜… è¿½åŠ : HTMLãƒ¬ãƒãƒ¼ãƒˆã‚‚å‡ºåŠ›ã™ã‚‹
            self.save_html_report(race_id, results)


        
    # ==========================================
    # ãƒ‡ãƒ¼ã‚¿åé›†
    # ==========================================
    def add_result(self, race_id):
        print(f"\nğŸ“¥ çµæœãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... (ID: {race_id})")
        time.sleep(1)
        url = f"https://db.netkeiba.com/race/{race_id}"
        
        try:
            res = requests.get(url, headers=self.headers)
            res.encoding = 'EUC-JP'
            soup = BeautifulSoup(res.text, 'html.parser')
            
            track, distance, weather, condition = self.get_race_info(soup)
            place_name = self.place_dict.get(race_id[4:6], "ãã®ä»–")
            
            dfs = pd.read_html(res.text)
            if not dfs: return
            
            df = None
            for d in dfs:
                if isinstance(d.columns, pd.MultiIndex): d.columns = [str(c[0]) for c in d.columns]
                d.columns = [str(c).replace(' ', '') for c in d.columns]
                if 'ç€é †' in d.columns: df = d; break
            
            if df is None: return

            df['race_id'] = str(race_id)
            df['site'] = place_name
            df['track'] = track
            df['distance'] = distance
            df['weather'] = weather
            df['condition'] = condition
            
            rename_map = {'ç€é †': 'ç€ é †', 'æ ç•ª': 'æ  ç•ª', 'é¦¬ç•ª': 'é¦¬ ç•ª', 'äººæ°—': 'äºº æ°—'}
            for k, v in rename_map.items():
                if k in df.columns: df = df.rename(columns={k: v})

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if str(race_id) in self.history_df['race_id'].astype(str).unique():
                print("âš ï¸ ã“ã®ãƒ¬ãƒ¼ã‚¹ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚")
                return

            # CSVè¿½è¨˜
            df.to_csv(self.csv_path, mode='a', header=not os.path.exists(self.csv_path), index=False, encoding="utf-8-sig")
            print("ğŸ’¾ ä¿å­˜ã—ã¾ã—ãŸã€‚")
            
            # ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ã‚‚æ›´æ–°
            self.history_df = pd.concat([self.history_df, df], axis=0)
            
            # è‡ªå‹•å†å­¦ç¿’ã™ã‚‹ã‹ç¢ºèª
            if input("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower() == 'y':
                self.retrain_models()

        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

    # ==========================================
    # â˜… å³å¯†ãªå†å­¦ç¿’ (æ™‚ç³»åˆ—åˆ†å‰² & Early Stopping)
    # ==========================================
    def retrain_models(self):
        print("\nğŸ”„ å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™ (Tuning -> Eval -> Finalize)...")
        
        # 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™
        if os.path.exists(self.csv_path):
            self.history_df = pd.read_csv(self.csv_path, dtype={'race_id': str}).dropna(subset=['race_id'])
        
        full_df = self.process_data(self.history_df).sort_values('race_id')
        
        if len(full_df) < 50:
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ã€‚æœ€ä½ã§ã‚‚5ãƒ¬ãƒ¼ã‚¹åˆ†ã»ã©é›†ã‚ã¦ãã ã•ã„ã€‚")
            return

        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰² (ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° & æ¤œè¨¼ç”¨)
        unique_ids = full_df['race_id'].unique()
        split_idx = int(len(unique_ids) * 0.8)
        
        train_ids = unique_ids[:split_idx]
        test_ids = unique_ids[split_idx:]
        
        df_train = full_df[full_df['race_id'].isin(train_ids)]
        df_test = full_df[full_df['race_id'].isin(test_ids)].copy()
        
        q_train = df_train.groupby('race_id').size().to_list()
        q_test = df_test.groupby('race_id').size().to_list()
        
        dtrain = lgb.Dataset(df_train[self.features], label=df_train['rank_label'], group=q_train)
        dtest = lgb.Dataset(df_test[self.features], label=df_test['rank_label'], group=q_test, reference=dtrain)

        # ==========================================
        # Phase 0: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Optuna)
        # ==========================================
        print("\n[Phase 0] ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢ä¸­ (Optuna)...")
        
        def objective(trial):
            params = {
                'objective': 'lambdarank',
                'metric': 'ndcg',
                'ndcg_eval_at': [1, 3],
                'verbosity': -1,
                'boosting_type': 'gbdt',
                'random_state': 42,
                'feature_pre_filter': False, 
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'max_depth': trial.suggest_int('max_depth', 5, 12),
                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),
            }
            
            # é«˜é€ŸåŒ–ã®ãŸã‚ã€ã“ã“ã§ã®å­¦ç¿’å›æ•°ã¯å°‘ãªã‚ã«
            model = lgb.train(
                params, dtrain, 
                valid_sets=[dtest], 
                valid_names=['eval'],
                num_boost_round=1000,
                callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]
            )
            return model.best_score['eval']['ndcg@1']

        # æ¢ç´¢å®Ÿè¡Œ (20å›è©¦è¡Œ)
        study = optuna.create_study(direction='maximize')
        study.optimize(objective, n_trials=20) 
        
        print(f"   âœ¨ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç™ºè¦‹: NDCG@1 = {study.best_value:.4f}")
        # ã‚¯ãƒ©ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°
        self.best_params.update(study.best_params)
        self.best_params['feature_pre_filter'] = False

        # ==========================================
        # Phase 1: æ€§èƒ½è©•ä¾¡ & æœ€é©å›æ•°æ±ºå®š
        # ==========================================
        print("\n[Phase 1] æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç›´è¿‘20%ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™...")
        
        seeds = [42, 100, 2024]
        val_models = []
        best_iterations = [] 
        
        for seed in seeds:
            params = self.best_params.copy()
            params['random_state'] = seed
            
            model = lgb.train(
                params, dtrain, 
                valid_sets=[dtest], 
                valid_names=['eval'],
                num_boost_round=5000,
                callbacks=[
                    lgb.early_stopping(stopping_rounds=50, verbose=False),
                    lgb.log_evaluation(period=0)
                ]
            )
            val_models.append(model)
            best_iterations.append(model.best_iteration)
        
        # è©•ä¾¡æŒ‡æ¨™ã®è¡¨ç¤º
        preds = []
        for model in val_models:
            preds.append(model.predict(df_test[self.features]))
        df_test['score'] = np.mean(preds, axis=0)
        
        results = []
        for rid, group in df_test.groupby('race_id'):
            ai_top1 = group.sort_values('score', ascending=False).iloc[0]
            is_win = 1 if ai_top1['ç€ é †'] == 1 else 0
            is_top3 = 1 if ai_top1['ç€ é †'] <= 3 else 0
            try: odds = float(ai_top1['å˜å‹'])
            except: odds = 0
            return_val = odds * 100 if is_win else 0
            results.append({'win': is_win, 'top3': is_top3, 'return': return_val})
            
        total = len(results)
        wins = sum(r['win'] for r in results)
        top3 = sum(r['top3'] for r in results)
        ret_money = sum(r['return'] for r in results)
        bet_money = total * 100
        
        print("\n" + "="*50)
        print(f" ğŸ“Š æ¤œè¨¼çµæœ (æœªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ {total} ãƒ¬ãƒ¼ã‚¹)")
        print("="*50)
        print(f" ğŸ¯ 1ç€ çš„ä¸­ç‡ : {(wins/total)*100:.1f}%")
        print(f" ğŸ¥‰ 3ç€å†…ç‡    : {(top3/total)*100:.1f}%")
        print(f" ğŸ’° å˜å‹å›åç‡ : {(ret_money/bet_money)*100:.1f}%")
        print("="*50)
        
        # ==========================================
        # Phase 2: å…¨ãƒ‡ãƒ¼ã‚¿ã§ã®æœ¬ç•ªå­¦ç¿’
        # ==========================================
        print("\n[Phase 2] æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®šã§å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã™...")
        
        # å°‘ã—å¤šã‚ã«å›ã™
        optimal_round = int(np.mean(best_iterations) * 1.1)
        print(f"   ğŸ‘‰ è¨­å®šãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°å›æ•°: {optimal_round}å›")
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        q_full = full_df.groupby('race_id').size().to_list()
        dtrain_full = lgb.Dataset(full_df[self.features], label=full_df['rank_label'], group=q_full)
        
        self.models = [] 
        
        for seed in seeds:
            print(f"   ğŸŒ± Seed {seed} Final Training...")
            params = self.best_params.copy()
            params['random_state'] = seed
            
            model = lgb.train(
                params, dtrain_full,
                num_boost_round=optimal_round,
                callbacks=[lgb.log_evaluation(period=0)]
            )
            joblib.dump(model, f'production_model_2026_seed_{seed}.pkl')
            self.models.append(model)
            
        print("âœ¨ å®Œå…¨å†å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # ==========================================
    # â˜… ç²¾åº¦æ¤œè¨¼ (Evaluation)
    # ==========================================
    def evaluate_performance(self):
        print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ã¨å›åç‡ã®æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™...")
        
        df = self.process_data(self.history_df).sort_values('race_id')
        unique_ids = df['race_id'].unique()
        
        if len(unique_ids) < 10:
            print("âš ï¸ æ¤œè¨¼ã™ã‚‹ã«ã¯ãƒ‡ãƒ¼ã‚¿ãŒã‚‚ã£ã¨å¿…è¦ã§ã™ã€‚")
            return

        test_size = int(len(unique_ids) * 0.2)
        test_ids = unique_ids[-test_size:]
        test_df = df[df['race_id'].isin(test_ids)].copy()
        
        preds = []
        for model in self.models:
            preds.append(model.predict(test_df[self.features]))
        test_df['score'] = np.mean(preds, axis=0)

        results = []
        for rid, group in test_df.groupby('race_id'):
            ai_top1 = group.sort_values('score', ascending=False).iloc[0]
            
            is_win = 1 if ai_top1['ç€ é †'] == 1 else 0
            is_top3 = 1 if ai_top1['ç€ é †'] <= 3 else 0
            
            try: odds = float(ai_top1['å˜å‹'])
            except: odds = 0
            
            return_val = odds * 100 if is_win else 0
            results.append({'win': is_win, 'top3': is_top3, 'return': return_val})

        total = len(results)
        wins = sum(r['win'] for r in results)
        top3 = sum(r['top3'] for r in results)
        ret_money = sum(r['return'] for r in results)
        bet_money = total * 100
        
        print("-" * 40)
        print(f" ğŸ§ª æ¤œè¨¼çµæœ (æœ€æ–° {total} ãƒ¬ãƒ¼ã‚¹)")
        print("-" * 40)
        print(f" ğŸ¯ 1ç€ çš„ä¸­ç‡ : {(wins/total)*100:.1f}% ({wins}/{total})")
        print(f" ğŸ¥‰ 3ç€å†…ç‡    : {(top3/total)*100:.1f}% ({top3}/{total})")
        print(f" ğŸ’° å˜å‹å›åç‡ : {(ret_money/bet_money)*100:.1f}% (æŠ•:{bet_money} -> å›:{int(ret_money)})")
        print("-" * 40)

    # ==========================================
    # â˜… ãƒ¢ãƒ‡ãƒ«ç›£æŸ» (è½ã¨ã—ç©´ãƒã‚§ãƒƒã‚¯)
    # ==========================================
    def audit_model(self):
        print("\nğŸ•µï¸â€â™€ï¸ ãƒ¢ãƒ‡ãƒ«ã®å¥å…¨æ€§ã‚’ç›£æŸ»ã—ã¾ã™ (Audit)...")
        
        # 1. ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ (æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿)
        df = self.process_data(self.history_df).sort_values('race_id')
        unique_ids = df['race_id'].unique()
        test_size = int(len(unique_ids) * 0.2)
        test_ids = unique_ids[-test_size:]
        test_df = df[df['race_id'].isin(test_ids)].copy()
        
        # äºˆæ¸¬
        preds = []
        for model in self.models:
            preds.append(model.predict(test_df[self.features]))
        test_df['score'] = np.mean(preds, axis=0)

        # é›†è¨ˆ
        results = []
        for rid, group in test_df.groupby('race_id'):
            ai_top1 = group.sort_values('score', ascending=False).iloc[0]
            is_win = 1 if ai_top1['ç€ é †'] == 1 else 0
            try: odds = float(ai_top1['å˜å‹'])
            except: odds = 0.0
            
            results.append({
                'race_id': rid, 
                'win': is_win, 
                'odds': odds, 
                'return': odds * 100 if is_win else 0,
                'horse': ai_top1['é¦¬å']
            })

        total_bet = len(results) * 100
        total_return = sum(r['return'] for r in results)
        base_recovery = (total_return / total_bet) * 100

        # --- â‘  ãƒã‚°ãƒ¬å½“ãŸã‚Šæ’é™¤ãƒ†ã‚¹ãƒˆ ---
        # å½“ãŸã£ãŸãƒ¬ãƒ¼ã‚¹ã‚’é…å½“ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        hits = sorted([r for r in results if r['win']], key=lambda x: x['odds'], reverse=True)
        
        print(f"\n1ï¸âƒ£ é«˜é…å½“ã¸ã®ä¾å­˜åº¦ãƒã‚§ãƒƒã‚¯")
        print(f"   ç¾åœ¨ã®å›åç‡: {base_recovery:.1f}%")
        
        if hits:
            # Top 3ã®é«˜é…å½“ã‚’è¡¨ç¤º
            print("   [å†…è¨³] é…å½“ãŒé«˜ã‹ã£ãŸçš„ä¸­ Top 3:")
            for i, h in enumerate(hits[:3]):
                print(f"     {i+1}. {h['horse']} (å˜å‹ {h['odds']}å€)")
            
            # Top 3ã‚’é™¤å¤–ã—ãŸå ´åˆã®å›åç‡
            top3_return_sum = sum(h['return'] for h in hits[:3])
            audit_return = total_return - top3_return_sum
            audit_recovery = (audit_return / total_bet) * 100
            
            print(f"   ğŸ‘‰ ã‚‚ã—ä¸Šä½3æœ¬ãŒå¤–ã‚Œã¦ã„ãŸã‚‰ -> å›åç‡: {audit_recovery:.1f}%")
            if audit_recovery < 100:
                print("      âš ï¸ è­¦å‘Š: å°‘æ•°ã®å¤§ç©´ã«ä¾å­˜ã—ã¦ã„ã¾ã™ã€‚é‹ã®è¦ç´ ãŒå¼·ã„ã§ã™ã€‚")
            else:
                print("      âœ… åˆæ ¼: ãƒ©ãƒƒã‚­ãƒ¼ãƒ‘ãƒ³ãƒæŠœãã§ã‚‚å‹ã¦ã¦ã„ã¾ã™ã€‚")
        else:
            print("   (çš„ä¸­ãªã—)")

        # --- â‘¡ ã‚ªãƒƒã‚ºä½ä¸‹ (ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸) ãƒ†ã‚¹ãƒˆ ---
        print(f"\n2ï¸âƒ£ ã‚ªãƒƒã‚ºä¸åˆ©ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        # å…¨ã¦ã®æ‰•ã„æˆ»ã—ã‚’ 0.9å€ (10%æ¸›) ã—ã¦è¨ˆç®—
        penalty_return = total_return * 0.9
        penalty_recovery = (penalty_return / total_bet) * 100
        print(f"   ğŸ‘‰ å¸¸ã«ã‚ªãƒƒã‚ºãŒ10%ä½ã‹ã£ãŸã‚‰ -> å›åç‡: {penalty_recovery:.1f}%")
        
        if penalty_recovery > 100:
            print("      âœ… åˆæ ¼: ã‚ªãƒƒã‚ºä½ä¸‹ã®èª¤å·®ã‚’å«ã‚ã¦ã‚‚ãƒ—ãƒ©ã‚¹ã§ã™ã€‚")
        else:
            print("      âš ï¸ æ³¨æ„: ã‚ªãƒƒã‚ºãŒå°‘ã—ä¸‹ãŒã‚‹ã ã‘ã§ãƒã‚¤ãƒŠã‚¹è»¢è½ã®å±é™ºãŒã‚ã‚Šã¾ã™ã€‚")

        # --- â‘¢ ãƒªãƒ¼ã‚¯ (ã‚«ãƒ³ãƒ‹ãƒ³ã‚°) ãƒã‚§ãƒƒã‚¯ ---
        print(f"\n3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯(ä¸æ­£è§£)ã®ç¢ºèª")
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¡¨ç¤º
        if self.models:
            importance = pd.DataFrame()
            importance['feature'] = self.features
            importance['gain'] = self.models[0].feature_importance(importance_type='gain')
            importance = importance.sort_values('gain', ascending=False).head(5)
            
            print("   [é‡è¦åº¦ Top 5 ç‰¹å¾´é‡]")
            for _, row in importance.iterrows():
                print(f"     - {row['feature']}")
            
            print("   ğŸ‘€ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:")
            print("      ãƒ»ã“ã“ã«ã€Œå½“æ—¥ã®ç€é †ã€ã€Œå½“æ—¥ã®ã‚¿ã‚¤ãƒ ã€ãªã©ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã‹ï¼Ÿ")
            print("      ãƒ»ã€Œå‰èµ°ã€œã€ã‚„ã€Œã‚ªãƒƒã‚º(ç¢ºå®šå‰)ã€ãªã‚‰OKã§ã™ã€‚")

    # ==========================================
    # â˜… è¿½åŠ æ©Ÿèƒ½: åŒæ—¥ä¸€æ‹¬å‡¦ç† (Batch Processing)
    # ==========================================
    def process_day_all(self, race_id, mode='predict'):
        """
        æŒ‡å®šã•ã‚ŒãŸrace_idã®æ—¥ä»˜ãƒ»å ´æ‰€æƒ…å ±ã‚’ä½¿ã„ã€1Rã‹ã‚‰12Rã¾ã§ã‚’ä¸€æ‹¬å‡¦ç†ã™ã‚‹
        mode: 'predict' (äºˆæƒ³) or 'result' (çµæœè¿½åŠ )
        """
        # IDã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ (ç°¡æ˜“)
        sid = str(race_id)
        if len(sid) != 12:
            print("âš ï¸ ã‚¨ãƒ©ãƒ¼: ãƒ¬ãƒ¼ã‚¹IDã¯12æ¡ã§å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: 202406010101)")
            return

        # æœ«å°¾2æ¡(ãƒ¬ãƒ¼ã‚¹ç•ªå·)ã‚’é™¤å¤–ã—ã¦ãƒ™ãƒ¼ã‚¹IDã‚’ä½œæˆ
        base_id = sid[:-2]
        
        print(f"\nğŸ”„ é–‹å‚¬æ—¥ä¸€æ‹¬å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™... (Base ID: {base_id}**)")
        print(f"   ãƒ¢ãƒ¼ãƒ‰: {'å…¨ãƒ¬ãƒ¼ã‚¹äºˆæƒ³' if mode == 'predict' else 'å…¨ãƒ¬ãƒ¼ã‚¹çµæœåé›†'}")

        # 1Rã€œ12Rã¾ã§ãƒ«ãƒ¼ãƒ—
        for i in range(1, 13):
            current_race_num = f"{i:02}"
            target_id = base_id + current_race_num
            
            print(f"\n{'='*60}")
            print(f" ğŸ‡ {current_race_num}R (ID: {target_id}) ã®å‡¦ç†ä¸­...")
            print(f"{'='*60}")
            
            if mode == 'predict':
                self.predict_race(target_id)
            elif mode == 'result':
                self.add_result(target_id)
            
            # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚ã€å°‘ã—é•·ã‚ã«å¾…æ©Ÿ
            print("   ğŸ’¤ å¾…æ©Ÿä¸­ (Access Interval)...")
            time.sleep(2)
        
        print(f"\nâœ… å…¨ãƒ¬ãƒ¼ã‚¹ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # ==========================================
    # â˜… æ–°è¦è¿½åŠ : äºˆæƒ³ãƒ­ã‚°ã®ä¿å­˜
    # ==========================================
    def save_prediction_log(self, race_id, df_results):
        import datetime
        now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ãƒ­ã‚°ã«æ®‹ã™ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        log_data = df_results.copy()
        log_data['timestamp'] = now
        log_data['race_id'] = str(race_id)
        
        # å¿…è¦ãªåˆ—ã ã‘ã«çµã‚‹
        cols = ['timestamp', 'race_id', 'é¦¬ ç•ª', 'é¦¬å', 'score_z', 'å˜å‹', 'status']
        # å­˜åœ¨ã—ãªã„åˆ—ãŒã‚ã‚Œã°åŸ‹ã‚ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        for c in cols:
            if c not in log_data.columns: log_data[c] = 0
            
        save_df = log_data[cols].rename(columns={
            'é¦¬ ç•ª': 'umaban',
            'é¦¬å': 'horse_name', 
            'å˜å‹': 'predicted_odds',
            'status': 'ai_status'
        })
        
        # çµæœè¨˜å…¥ç”¨ã®ç©ºåˆ—ã‚’è¿½åŠ 
        save_df['actual_rank'] = np.nan   # å®Ÿéš›ã®ç€é †
        save_df['actual_odds'] = np.nan   # ç¢ºå®šã‚ªãƒƒã‚º
        save_df['return_amount'] = 0      # æ‰•æˆ»é‡‘
        
        # æ—¢å­˜ãƒ­ã‚°ãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚“ã§ã€ä»Šå›ã®ãƒ¬ãƒ¼ã‚¹IDã®åˆ†ã‚’ä¸€åº¦æ¶ˆã™ï¼ˆä¸Šæ›¸ãã®ãŸã‚ï¼‰
        if os.path.exists(self.log_path):
            existing_log = pd.read_csv(self.log_path, dtype={'race_id': str})
            # åŒã˜ãƒ¬ãƒ¼ã‚¹IDã®è¨˜éŒ²ãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦ã€æ–°ã—ã„äºˆæƒ³ã«å…¥ã‚Œæ›¿ãˆã‚‹
            existing_log = existing_log[existing_log['race_id'] != str(race_id)]
            final_df = pd.concat([existing_log, save_df], axis=0)
        else:
            final_df = save_df

        final_df.to_csv(self.log_path, index=False, encoding='utf-8-sig')
        print(f"   ğŸ“ äºˆæƒ³ãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {self.log_path}")

    # ==========================================
    # â˜… æ±ºå®šç‰ˆ: äºˆæƒ³çµæœã®ç­”ãˆåˆã‚ã› (ã‚ªãƒƒã‚ºåˆ—å è‡ªå‹•è£œæ­£æ©Ÿèƒ½ä»˜ã)
    # ==========================================
    def settle_predictions(self, race_id):
        if not os.path.exists(self.log_path):
            print("âš ï¸ äºˆæƒ³ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«äºˆæƒ³ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
            return

        print(f"\nğŸ’° ãƒ¬ãƒ¼ã‚¹çµæœã‚’ç…§åˆä¸­... (ID: {race_id})")
        
        # 1. ãƒãƒƒãƒˆç«¶é¦¬ã®ã€Œé€Ÿå ±çµæœã€ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"
        
        try:
            res = requests.get(url, headers=self.headers)
            res.encoding = 'EUC-JP'
            
            dfs = pd.read_html(res.content)
            if not dfs:
                print("âŒ çµæœãƒ‡ãƒ¼ã‚¿ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return
            
            # çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
            result_df = None
            for d in dfs:
                # åˆ—åã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆæ”¹è¡Œã‚„ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»ï¼‰
                cols = [str(c).replace('\n', '').replace(' ', '') for c in d.columns]
                d.columns = cols
                
                # â˜… å¼·åŠ›ãªè£œæ­£: ã€Œå˜å‹ã‚ªãƒƒã‚ºã€ã‚„ã€Œå˜å‹ã€ãŒå«ã¾ã‚Œã‚‹åˆ—ã‚’æ¢ã—ã¦ã€Œå˜å‹ã€ã«çµ±ä¸€
                odds_col = next((c for c in cols if 'å˜å‹' in c), None)
                if odds_col:
                    d = d.rename(columns={odds_col: 'å˜å‹'})

                # ã€Œç€é †ã€ã¨ã€Œé¦¬ç•ªã€ãŒã‚ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¡ç”¨
                if 'ç€é †' in d.columns and 'é¦¬ç•ª' in d.columns:
                    result_df = d
                    break
            
            if result_df is None:
                print("â³ ã¾ã ãƒ¬ãƒ¼ã‚¹çµæœãŒç¢ºå®šã—ã¦ã„ãªã„ã‹ã€ãƒšãƒ¼ã‚¸æ§‹é€ ãŒç•°ãªã‚Šã¾ã™ã€‚")
                return

            # --- ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ› ---
            # é¦¬ç•ª
            result_df['é¦¬ç•ª'] = pd.to_numeric(result_df['é¦¬ç•ª'], errors='coerce')
            result_df = result_df.dropna(subset=['é¦¬ç•ª'])
            result_df['é¦¬ç•ª'] = result_df['é¦¬ç•ª'].astype(int)
            
            # ç€é †
            def parse_rank(x):
                try: return int(x)
                except: return 99
            
            result_df['ç€é †_num'] = result_df['ç€é †'].apply(parse_rank)
            
            # å˜å‹ã‚ªãƒƒã‚ºï¼ˆæ•°å€¤åŒ–ï¼‰
            if 'å˜å‹' in result_df.columns:
                result_df['å˜å‹'] = pd.to_numeric(result_df['å˜å‹'], errors='coerce').fillna(0.0)
            else:
                result_df['å˜å‹'] = 0.0

            # 2. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            log_df = pd.read_csv(self.log_path, dtype={'race_id': str})
            
            target_mask = log_df['race_id'] == str(race_id)
            if not target_mask.any():
                print("âš ï¸ ã“ã®ãƒ¬ãƒ¼ã‚¹ã®äºˆæƒ³ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return

            # 3. ãƒãƒ¼ã‚¸ã—ã¦çµæœã‚’æ›´æ–°
            buy_keywords = ['æœ¬å‘½', 'å¦™å‘³', 'çˆ†ç©´', 'ğŸ”¥ğŸ”¥', 'âš ï¸', 'ğŸ§ª']
            count_updated = 0
            
            for idx, row in log_df[target_mask].iterrows():
                try:
                    umaban = int(row['umaban'])
                    match = result_df[result_df['é¦¬ç•ª'] == umaban]
                    
                    if len(match) > 0:
                        top_row = match.iloc[0]
                        actual_rank = int(top_row['ç€é †_num'])
                        final_odds = float(top_row['å˜å‹'])
                        
                        # ãƒ­ã‚°æ›´æ–°
                        log_df.at[idx, 'actual_rank'] = actual_rank
                        log_df.at[idx, 'actual_odds'] = final_odds
                        
                        # æ‰•ã„æˆ»ã—è¨ˆç®— (è³¼å…¥å¯¾è±¡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ã¿)
                        status = str(row['ai_status'])
                        if any(k in status for k in buy_keywords):
                            if actual_rank == 1:
                                log_df.at[idx, 'return_amount'] = int(final_odds * 100)
                            else:
                                log_df.at[idx, 'return_amount'] = 0
                        else:
                             log_df.at[idx, 'return_amount'] = 0
                        
                        count_updated += 1
                except:
                    continue

            # ä¿å­˜
            log_df.to_csv(self.log_path, index=False, encoding='utf-8-sig')
            
            # --- ä»Šå›ã®çµæœãƒ¬ãƒãƒ¼ãƒˆ ---
            race_log = log_df[target_mask]
            buy_mask = race_log['ai_status'].astype(str).apply(lambda x: any(k in x for k in buy_keywords))
            
            this_bet = len(race_log[buy_mask]) * 100
            this_return = race_log['return_amount'].sum()
            this_balance = this_return - this_bet
            
            winner_row = result_df[result_df['ç€é †_num']==1]
            winner_name = winner_row['é¦¬å'].values[0] if len(winner_row)>0 else 'ä¸æ˜'
            winner_odds = winner_row['å˜å‹'].values[0] if len(winner_row)>0 else 0.0
            
            print("-" * 30)
            print(f" ğŸ {race_id} çµæœæ›´æ–° ({count_updated}é ­)")
            print(f" ğŸ¥‡ 1ç€: {winner_name} (å˜å‹ {winner_odds}å€)")  # â˜…ã“ã“ã«ã‚ªãƒƒã‚ºãŒå‡ºã‚‹ã¯ãšã§ã™
            print(f" ğŸ« æŠ•è³‡: {this_bet}å†† -> å›å: {int(this_return)}å††")
            print(f" ğŸ“Š åæ”¯: {'+' if this_balance >= 0 else ''}{int(this_balance)}å††")
            
            # --- å…¨æœŸé–“ãƒˆãƒ¼ã‚¿ãƒ« ---
            total_log = log_df.dropna(subset=['actual_rank'])
            total_buy_mask = total_log['ai_status'].astype(str).apply(lambda x: any(k in x for k in buy_keywords))
            total_bet_calc = len(total_log[total_buy_mask]) * 100
            total_return_calc = total_log[total_buy_mask]['return_amount'].sum()
            total_balance_calc = total_return_calc - total_bet_calc
            
            print("=" * 30)
            print(f" ğŸ’° å…¨æœŸé–“ãƒˆãƒ¼ã‚¿ãƒ«åæ”¯: {'+' if total_balance_calc >= 0 else ''}{int(total_balance_calc):,} å††")
            print("=" * 30)
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()

    # ==========================================
    # â˜… ä¿®æ­£ç‰ˆ: æ¤œç´¢æ©Ÿèƒ½ä»˜ãHTMLãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    # ==========================================
    def save_html_report(self, race_id, df):
        import datetime
        today_str = datetime.datetime.now().strftime('%Y%m%d')
        filename = f"report_{today_str}.html"
        
        now_str = datetime.datetime.now().strftime('%H:%M:%S')
        
        # HTMLãƒ˜ãƒƒãƒ€ãƒ¼ (CSS + JS)
        html_header = """
        <html>
        <head>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <title>AI Keiba Report</title>
            <style>
                body { font-family: "Helvetica Neue", Arial, sans-serif; background-color: #f4f4f9; color: #333; padding: 20px; padding-top: 80px; }
                
                /* æ¤œç´¢ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ« (ä¸Šéƒ¨å›ºå®š) */
                .search-container {
                    position: fixed; top: 0; left: 0; width: 100%;
                    background: #343a40; padding: 15px; box-shadow: 0 2px 5px rgba(0,0,0,0.2);
                    z-index: 1000; display: flex; align-items: center; justify-content: center;
                }
                .search-box {
                    width: 300px; padding: 10px; border-radius: 5px; border: none; font-size: 16px;
                    outline: none;
                }
                .search-label { color: white; margin-right: 10px; font-weight: bold; }
                
                /* ã‚«ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ« */
                .race-card { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); margin-bottom: 30px; animation: fadeIn 0.5s; }
                h2 { border-bottom: 2px solid #007bff; padding-bottom: 10px; color: #0056b3; margin-top: 0; }
                .meta { color: #666; font-size: 0.9em; margin-bottom: 15px; }
                
                /* ãƒ†ãƒ¼ãƒ–ãƒ« */
                table { width: 100%; border-collapse: collapse; margin-top: 10px; }
                th { background-color: #007bff; color: white; padding: 10px; text-align: left; }
                td { padding: 10px; border-bottom: 1px solid #ddd; }
                
                /* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è‰² */
                .status-fire { background-color: #ffebee; color: #c62828; font-weight: bold; border-left: 5px solid #d32f2f; }
                .status-warn { background-color: #fff3e0; color: #ef6c00; font-weight: bold; border-left: 5px solid #f57c00; }
                .status-safe { background-color: #e3f2fd; color: #1565c0; border-left: 5px solid #1976d2; }
                .status-wait { color: #999; }
                
                @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
            </style>
            <script>
                // æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½
                function filterRaces() {
                    var input = document.getElementById('raceInput').value.toLowerCase();
                    var cards = document.getElementsByClassName('race-card');
                    
                    for (var i = 0; i < cards.length; i++) {
                        var raceId = cards[i].getAttribute('data-race-id');
                        var text = cards[i].innerText.toLowerCase();
                        
                        // IDãŒä¸€è‡´ã™ã‚‹ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆ(11Rãªã©)ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°è¡¨ç¤º
                        if (raceId.includes(input) || text.includes(input)) {
                            cards[i].style.display = "";
                        } else {
                            cards[i].style.display = "none";
                        }
                    }
                }
            </script>
        </head>
        <body>
        
        <div class="search-container">
            <span class="search-label">ğŸ” Race Search:</span>
            <input type="text" id="raceInput" class="search-box" onkeyup="filterRaces()" placeholder="ID or Race No (e.g. 11, 2024...)">
        </div>
        
        <div style="text-align:center; margin-bottom:20px; color:#666;">
            <h1>ğŸ‡ AI Keiba Daily Report</h1>
        </div>
        """
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿æ›¸ããƒ¢ãƒ¼ãƒ‰è¨­å®š
        mode = 'a' if os.path.exists(filename) else 'w'
        
        with open(filename, mode, encoding='utf-8') as f:
            if mode == 'w':
                f.write(html_header)
            
            # --- é‡è¦ãªå¤‰æ›´ç‚¹: data-race-id å±æ€§ã‚’è¿½åŠ  ---
            f.write(f'<div class="race-card" data-race-id="{race_id}">')
            
            # ãƒ¬ãƒ¼ã‚¹ç•ªå·ã®æŠ½å‡ºï¼ˆIDã®æœ«å°¾2æ¡ï¼‰
            try: race_num = f"{int(race_id[-2:]):02}R"
            except: race_num = "Unknown R"

            f.write(f'<h2>ğŸ“ {race_num} (ID: {race_id}) <span style="font-size:0.6em; float:right;">{now_str}</span></h2>')
            
            place = df['site'].iloc[0] if 'site' in df.columns else '-'
            cond = f"{df['distance'].iloc[0]}m / {df['weather'].iloc[0]}" if 'distance' in df.columns else ''
            f.write(f'<div class="meta">ğŸŸï¸ {place} | ğŸŒ¤ï¸ {cond}</div>')
            
            f.write('<table>')
            f.write('<thead><tr><th>Rank</th><th>No.</th><th>é¦¬å</th><th>AIæŒ‡æ•°</th><th>Odds</th><th>åˆ¤å®š</th></tr></thead>')
            f.write('<tbody>')
            
            for i, row in df.iterrows():
                score = row['score_z']
                odds = float(row['å˜å‹'])
                
                row_class = ""
                status_text = "-"
                
                if score > 1.5:
                    if odds >= 30.0: 
                        row_class = "status-fire"; status_text = "ğŸ§ª çˆ†ç©´"
                    elif odds >= 5.0: 
                        row_class = "status-fire"; status_text = "ğŸ”¥ğŸ”¥ å¦™å‘³"
                    elif odds == 0:
                        row_class = "status-wait"; status_text = "â³ ã‚ªãƒƒã‚ºå¾…"
                    else: 
                        row_class = "status-warn"; status_text = "âš ï¸ æœ¬å‘½"
                elif score > 0.8:
                    row_class = "status-safe"; status_text = "â–³ æŠ‘ãˆ"
                
                f.write(f'<tr class="{row_class}">')
                f.write(f'<td>{i+1}</td>')
                f.write(f'<td>{row["é¦¬ ç•ª"]}</td>')
                f.write(f'<td><b>{row["é¦¬å"]}</b></td>')
                f.write(f'<td>{score:.2f}</td>')
                f.write(f'<td>{odds}</td>')
                f.write(f'<td>{status_text}</td>')
                f.write('</tr>')
                
            f.write('</tbody></table></div>')
            
        print(f"   âœ¨ ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›: {filename}")
    # ==========================================
    # â˜… ä¿®æ­£ç‰ˆ: åæ”¯åˆ†æã¨ã‚°ãƒ©ãƒ•åŒ– (ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆä»˜ã)
    # ==========================================
    def analyze_log(self):
        import matplotlib.pyplot as plt
        
        if not os.path.exists(self.log_path):
            print("âš ï¸ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«äºˆæƒ³ã¨ç­”ãˆåˆã‚ã›ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
            return

        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(self.log_path)
        
        # çµæœãŒç¢ºå®šã—ã¦ã„ã‚‹ï¼ˆç€é †ãŒå…¥ã£ã¦ã„ã‚‹ï¼‰ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
        df = df.dropna(subset=['actual_rank'])
        
        if len(df) == 0:
            print("âš ï¸ çµæœãŒç¢ºå®šã—ãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œ3. ç­”ãˆåˆã‚ã›ã€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
            return

        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­... (å…¨ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)} ä»¶)")

        # --- åæ”¯è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ ---
        # è³¼å…¥å¯¾è±¡ã¨ãªã‚‹ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        buy_keywords = ['æœ¬å‘½', 'å¦™å‘³', 'çˆ†ç©´', 'ğŸ”¥ğŸ”¥', 'âš ï¸', 'ğŸ§ª']
        
        # è³¼å…¥ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        # ai_statusåˆ—ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°è³¼å…¥å¯¾è±¡(100å††)ã€ãã†ã§ãªã‘ã‚Œã°0å††
        df['is_buy'] = df['ai_status'].astype(str).apply(lambda x: any(k in x for k in buy_keywords))
        df['bet_amount'] = df['is_buy'].apply(lambda x: 100 if x else 0)
        
        # æ‰•æˆ»é‡‘ï¼ˆçµæœãŒãªã„å ´åˆã¯0ï¼‰
        df['return_amount'] = df['return_amount'].fillna(0)
        
        # è³¼å…¥ã—ãŸè¡Œã ã‘ã‚’æŠ½å‡º
        bet_df = df[df['is_buy']].copy()
        
        if len(bet_df) == 0:
            print("âš ï¸ æ¨å¥¨é¦¬ï¼ˆè³¼å…¥å¯¾è±¡ï¼‰ã®è¨˜éŒ²ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        # é›†è¨ˆ
        total_bet = bet_df['bet_amount'].sum()
        total_return = bet_df['return_amount'].sum()
        total_balance = total_return - total_bet
        recovery_rate = (total_return / total_bet * 100) if total_bet > 0 else 0
        
        win_count = len(bet_df[bet_df['actual_rank'] == 1])
        total_races = len(bet_df)
        win_rate = (win_count / total_races * 100) if total_races > 0 else 0

        # --- ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¸ã®åæ”¯ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ› ---
        print("\n" + "="*40)
        print(" ğŸ’° æ¨å¥¨é¦¬è³¼å…¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (å˜å‹100å††)")
        print("="*40)
        print(f" ğŸ« è³¼å…¥ç·æ•°   : {total_races} é ­")
        print(f" ğŸ¯ çš„ä¸­æ•°     : {win_count} é ­ (çš„ä¸­ç‡ {win_rate:.1f}%)")
        print("-" * 40)
        print(f" ğŸ’´ ç·æŠ•è³‡é¡   : {int(total_bet):,} å††")
        print(f" ğŸ’´ ç·æ‰•æˆ»é¡   : {int(total_return):,} å††")
        print(f" ğŸ“ˆ å›åç‡     : {recovery_rate:.1f} %")
        print("-" * 40)
        if total_balance >= 0:
            print(f" ğŸ’¹ æœ€çµ‚åæ”¯   : +{int(total_balance):,} å†† ğŸ”µ")
        else:
            print(f" ğŸ“‰ æœ€çµ‚åæ”¯   : {int(total_balance):,} å†† ğŸ”´")
        print("="*40)

        # --- ä»¥ä¸‹ã€ã‚°ãƒ©ãƒ•ä½œæˆï¼ˆæ—¢å­˜æ©Ÿèƒ½ã®ç¶­æŒãƒ»å¼·åŒ–ï¼‰ ---
        try:
            # æ™‚ç³»åˆ—åæ”¯
            bet_df['profit'] = bet_df['return_amount'] - bet_df['bet_amount']
            bet_df['balance_history'] = bet_df['profit'].cumsum()
            
            plt.figure(figsize=(10, 5))
            plt.plot(range(len(bet_df)), bet_df['balance_history'], marker='o', linestyle='-', color='blue')
            plt.axhline(y=0, color='r', linestyle='--')
            plt.title(f'Balance History (Total: {int(total_balance)} Yen)')
            plt.xlabel('Number of Bets')
            plt.ylabel('Balance (Yen)')
            plt.grid(True)
            plt.savefig('analysis_balance.png')
            plt.close()
            print("   ğŸ“¸ åæ”¯æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: analysis_balance.png")
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥åˆ†æ
            def get_simple_status(txt):
                if 'çˆ†ç©´' in txt or 'ğŸ§ª' in txt: return 'ç©´(Risk)'
                if 'å¦™å‘³' in txt or 'ğŸ”¥ğŸ”¥' in txt: return 'å¦™(Value)'
                if 'æœ¬å‘½' in txt or 'âš ï¸' in txt: return 'æœ¬(Solid)'
                return 'Other'
            
            bet_df['type'] = bet_df['ai_status'].apply(get_simple_status)
            status_summary = bet_df.groupby('type').agg({
                'bet_amount': 'count',
                'return_amount': 'sum'
            })
            status_summary['recov'] = (status_summary['return_amount'] / (status_summary['bet_amount'] * 100)) * 100
            
            print("\nğŸ“‹ ã‚¿ã‚¤ãƒ—åˆ¥æˆç¸¾:")
            print(tabulate(status_summary[['bet_amount', 'recov']], headers=['Type', 'Count', 'Recov%'], tablefmt='simple'))

        except Exception as e:
            print(f"âš ï¸ ã‚°ãƒ©ãƒ•ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    system = KeibaSystem()
    while True:
        print("\n=== ğŸ‡ AI Keiba System 2026 (Pro) ===")
        print("1. äºˆæƒ³ (IDå…¥åŠ› -> å˜ç™º/å…¨ãƒ¬ãƒ¼ã‚¹é¸æŠå¯)")
        print("2. çµæœè¿½åŠ  (IDå…¥åŠ› -> å˜ç™º/å…¨ãƒ¬ãƒ¼ã‚¹é¸æŠå¯)")
        print("3. â˜… äºˆæƒ³ã®ç­”ãˆåˆã‚ã› (åæ”¯è¨˜éŒ²)")
        print("4. â˜… åæ”¯ãƒ»åˆ†æã‚°ãƒ©ãƒ•å‡ºåŠ›") # è¿½åŠ 
        print("5. å¼·åˆ¶å†å­¦ç¿’ (Rigorous)")
        print("6. ç²¾åº¦æ¤œè¨¼ (Eval)")
        print("7. è½ã¨ã—ç©´ãƒã‚§ãƒƒã‚¯ (Audit)")
        print("8. çµ‚äº†")
        
        c = input("é¸æŠ: ")
        
        if c == '1':
            rid = input("Race ID (ä»£è¡¨): ")
            sub_c = input("   [1] ã“ã®ãƒ¬ãƒ¼ã‚¹ã®ã¿äºˆæƒ³  [2] ã“ã®æ—¥ã®å…¨12ãƒ¬ãƒ¼ã‚¹ã‚’äºˆæƒ³ : ")
            if sub_c == '2':
                system.process_day_all(rid, mode='predict')
            else:
                system.predict_race(rid)

        elif c == '2':
            rid = input("Race ID (ä»£è¡¨): ")
            sub_c = input("   [1] ã“ã®ãƒ¬ãƒ¼ã‚¹ã®ã¿è¿½åŠ   [2] ã“ã®æ—¥ã®å…¨12ãƒ¬ãƒ¼ã‚¹ã‚’è¿½åŠ  : ")
            if sub_c == '2':
                system.process_day_all(rid, mode='result')
            else:
                system.add_result(rid)
        
        elif c == '3':
            # â˜… æ–°è¦è¿½åŠ 
            rid = input("Race ID (ç­”ãˆåˆã‚ã›ã—ãŸã„ãƒ¬ãƒ¼ã‚¹): ")
            sub_c = input("   [1] å˜ç™º  [2] ã“ã®æ—¥ã®å…¨ãƒ¬ãƒ¼ã‚¹ã‚’ä¸€æ‹¬å‡¦ç† : ")
            if sub_c == '2':
                # process_day_all ã« settle ãƒ¢ãƒ¼ãƒ‰ã‚’è¿½åŠ ã™ã‚‹ã‹ã€ãƒ«ãƒ¼ãƒ—ã§å›ã™
                base_id = rid[:-2]
                for i in range(1, 13):
                    target = base_id + f"{i:02}"
                    system.settle_predictions(target)
                    time.sleep(1)
            else:
                system.settle_predictions(rid)
        elif c == '4':
            system.analyze_log() # å‘¼ã³å‡ºã—

        elif c == '5': system.retrain_models()
        elif c == '6': system.evaluate_performance()
        elif c == '7': system.audit_model()
        elif c == '8': break